<!DOCTYPE HTML>
<html>

<head>
  <!-- Google analytics tag (gtag.js) -->
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-STGLQW4BJX');
  </script>

  <!-- Title -->
  <title>Mozhgan Pourkeshavarz</title>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=1000">

  <!-- Isotope JS -->
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.1/jquery.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/jqueryui/1.13.2/jquery-ui.min.js"></script>
  <script src="https://unpkg.com/isotope-layout@3/dist/isotope.pkgd.min.js"></script>

  <!-- Custom Style -->
  <link rel="stylesheet" href="style.css">
  <link rel="icon" href="images/ut_logo.jpg">

  <!-- Google Font -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link
    href="https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap"
    rel="stylesheet">
  <style>
    @import url('https://fonts.googleapis.com/css2?family=Asap:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;1,100;1,200;1,300;1,400;1,500;1,600;1,700&display=swap');

    .experience::after {
      content: '';
      position: absolute;
      width: 2px;
      background-color: #abadb3;
      top: 0px;
      bottom: 0;
      left: 72px;
      margin: 20px 0px;
      margin-left: -3px;
    }

    .container {
      padding: 10px 0px;
      position: relative;
      background-color: inherit;
      width: 100%;
      display: flex;
      align-items: center;
    }

    .container img {
      width: 50px;
      padding: 10px 20px 0px 40px;
      justify-self: left;
    }

    .timeline::after {
      content: '';
      position: absolute;
      width: 5px;
      height: 5px;
      left: 65.5px;
      background-color: #5b5c5f;
      border: 2px solid #5b5c5f;
      border-radius: 50%;
      z-index: 1;
    }

    .content {
      padding: 20px 30px;
      background-color: white;
      position: relative;
      border-radius: 6px;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }

    .content img {
      width: 50px;
      height: auto;
      vertical-align: middle;
      margin-right: 10px;
    }

    .p-exp {
      line-height: 1.5em;
    }

    .container > img {
      width: 55px;
    }
  </style>
</head>

<body id="body">

  <div id="main">
    <div id="intro">
      <div id="intro-text">
        <h1>Mozhgan Pourkeshavarz</h1>
        <p>
          <span style="font-size: 24px;"> > Hello, World!</span>
           </br> </br>
          I am a Senior Research Scientist at Noah's Ark Lab, <a href="https://www.noahlab.com.hk/#/home">Huawei Research Canada</a>, working in the Embodied AI (EAI) team. My research bridges computer vision, machine learning, and robotics, aiming to develop methods that enable autonomous vehicles to navigate dynamic environments safely. My primary focus includes motion forecasting and scene reasoning, with particular emphasis on achieving generalization and robustness in unseen domains and long-tail driving scenarios. Earlier in my career, my work concentrated on computer vision, and I had the opportunity to collaborate with <a href="https://sabokrou.github.io/">Mohammad Sabokrou</a> and <a href="https://gyzhao-nm.github.io/Guoying/">Guoying Zhao</a>.
          <br><br>
          I earned my masterâ€™s degree in computer science, specializing in artificial intelligence and robotics, with highest honors from <a href="https://en.sbu.ac.ir/">Shahid Beheshti University</a> in 2021. Prior to that, I obtained my bachelorâ€™s degree in computer software engineering from <a href="https://shirazu.ac.ir/en/home">Shiraz University</a> in 2017.

        <br><br>
        <a href="https://scholar.google.com/citations?user=crjO2y8AAAAJ&hl=en">G. Scholar</a>&nbsp;&nbsp;&nbsp;/ &nbsp;
        <a href="https://www.linkedin.com/in/mpourkeshavarz/">LinkedIn</a>&nbsp;&nbsp;&nbsp;&nbsp;

        <br><br>
        I am open to collaborations, feel free to reach out!
        <br>
        m.pourkeshavarz at gmail dot com
        <br><br>
        </p>
      </div>
      <div id="intro-image">
        <img src="images/profile.jpg">
      </div>
    </div>

    <div id="filters" class="button-group">
      <button class="button" data-filter=".talk">Highlights</button>
      <button class="button" data-filter=".experience">Experience</button>
      <button class="button" data-filter=".publication">Research</button>
<!--      <button class="button" data-filter=".misc">Misc</button>-->
    </div>




    <div class="grid">

          <!-- Highlights -->
      <div class="list-item talk" data-category="talk">
        <p class="date">Nov-2024</p>ðŸ“š I am looking for a PhD position in the field of autonomous driving.
      </div>

      <div class="list-item talk" data-category="talk">
        <p class="date">Sep-2024</p>Iâ€™ll be attending ECCV 2024 in Milan. If youâ€™ll be there too and share an interest in autonomous driving, Iâ€™d be happy to connect!
      </div>

      <div class="list-item talk" data-category="talk">
        <p class="date">July-2024</p>ðŸš€ our paper "DySeT: a Dynamic Masked Self-distillation Approach for Robust Trajectory Prediction" has been accepted to ECCV 2024!
      </div>


      <div class="list-item talk" data-category="talk">
        <p class="date">July-2024</p>Iâ€™m heading to ICML 2024 in Vienna!
      </div>

    <div class="list-item talk" data-category="talk">
        <p class="date">Feb-2024</p>ðŸ”¥ I'm happy to share the acceptance of two papers at CVPR 2024!
    </div>


      <div class="list-item talk" data-category="talk">
        <p class="date">July-2023</p>ðŸ“¢ Excited to share that our paper "Learn TAROT with MENTOR: A Meta-Learned Self-supervised Approach for Trajectory Prediction" got accepted to ICCV 2023!
      </div>

      <div class="list-item talk" data-category="talk">
        <p class="date">Jun-2023</p>Iâ€™ll be attending CVPR 2023 in beautiful Vancouver!
      </div>

        <!-- Experiences -->
      <div class="list-item experience" data-category="experience">
        <div class="container left">
          <div class="date">2022.09 - Present</div>
          <div class="timeline"></div>
          <img src="images/Huawei-Logo.png" alt="Huawei">
          <div class="content">
            <p class="p-exp">Senior Research Scientist at <a href="https://www.noahlab.com.hk/#/home">Noah's Ark Lab</a>, with <a
                href="https://aras62.github.io/">Amir Rasouli</a> at Huawei Research Canada. I have been working on motion prediction for autonomous vehicles, with a focus on scene understanding [<a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.pdf">ICCV 2023</a>], causal reasoning and domain generalization [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Pourkeshavarz_CaDeT_a_Causal_Disentanglement_Approach_for_Robust_Trajectory_Prediction_in_CVPR_2024_paper.pdf">CVPR 2024</a>, <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00414.pdf">ECCV 2024</a>, <a href="https://arxiv.org/pdf/2404.12538">IV 2024</a>], and trustworthiness [<a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Pourkeshavarz_Adversarial_Backdoor_Attack_by_Naturalistic_Data_Poisoning_on_Trajectory_Prediction_CVPR_2024_paper.pdf">CVPR 2024</a>, <a href="https://arxiv.org/pdf/2310.07794">ICRA 2024</a>].
            </p>
          </div>
        </div>

        <div class="container left">
          <div class="date">2021.09 - 2022.08</div>
          <div class="timeline"></div>
          <img src="images/mtl.jpeg" alt="mtl.ai">
          <div class="content">
            <p class="p-exp">Machine Learning Engineer at the <a href="https://mtl.ai/">mtl.ai.</a> I developed object detection and segmentation methods for real-time virtual advertisement software in live sports broadcasts.
            </p>
          </div>
        </div>

        <div class="container left">
          <div class="date">2020.09 - 2021.09</div>
          <div class="timeline"></div>
          <img src="images/ipm.jpeg" alt="IPM">
          <div class="content">

            <p class="p-exp"> Research Assistant at <a href="https://ipm.ir/">
IPM Institute For Research In Fundamental Sciences</a>, supervised by <a
                href="https://sabokrou.github.io/">Mohammad Sabokrou</a>. I Researched methods to address catastrophic forgetting in the incremental training of deep neural networks, with applications in computer vision [<a href="https://openreview.net/pdf?id=RxplU3vmBx">ICLR 2022</a>].
            </p>
          </div>
        </div>

        <div class="container left">
          <div class="date">2019.09 - 2020.09</div>
          <div class="timeline"></div>
          <img src="images/bmn.png" alt="bmn">

          <div class="content">
            <p class="p-exp">Research Engineer at the <a href="https://en.bmn.ir/">Iran's National Elites Foundation (INEF).</a> I Designed and developed video event detection methods in sports.
            </p>
          </div>
        </div>

        <div class="container left">
          <div class="date">2018.06 - 2019.06</div>
          <div class="timeline"></div>
          <img src="images/med.png" alt="IPM">
          <div class="content">

            <p class="p-exp"> Volunteer Researcher  at <a href="https://rhc.ac.ir/en/page/3686/deputy-of-research">
              Rajaei Cardiovascular, Medical & Research Center</a>, with <a
                href="https://www.cs.ubc.ca/people/mehrdad-oveisi">Mehrdad Oveisi.</a> In collaboration with medical professionals, I conducted research and developed AI-powered tools to address challenges in diagnosis, treatment planning, and patient care [<a href="https://journal.zums.ac.ir/browse.php?a_id=6918&sid=1&slc_lang=en&html=1">Adv Med Biomed Res</a>, <a href="https://www.sciencedirect.com/science/article/abs/pii/S1071358123016689">Nuclear Cardiology</a>].
            </p>
          </div>
        </div>
      </div>


      <!-- Publications -->
      <div class="list-item publication" data-category="publication">
        <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00414.pdf" class="thumbnail">
            <img src="images/DySet.png" alt="" />
        </a>
        <div class="project-description">
          <h3><a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00414.pdf">
            <span style="color: balck; font-weight;">DySeT: A Dynamic Masked Self-distillation Approach for Robust Trajectory Prediction</span>
<!--              DySeT: A Dynamic Masked Self-distillation Approach for Robust Trajectory Prediction-->
            </a></h3>
          <p>
            <span style="color: black; font-weight: bold;">Mozhgan Pourkeshavarz</span>, Junrui Zhang, Amir Rasouli<br>
            <i>European Conference on Computer Vision (<a href="https://eccv.ecva.net/"> ECCV 2024 </a>)</i><br>
<!--            <a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00414.pdf">PDF</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;-->
          </p>
        </div>
      </div>


        <div class="list-item publication" data-category="publication">
        <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Pourkeshavarz_Adversarial_Backdoor_Attack_by_Naturalistic_Data_Poisoning_on_Trajectory_Prediction_CVPR_2024_paper.pdf" class="thumbnail">
            <img src="images/advers.png" alt="" />
        </a>
        <div class="project-description">
          <h3><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Pourkeshavarz_Adversarial_Backdoor_Attack_by_Naturalistic_Data_Poisoning_on_Trajectory_Prediction_CVPR_2024_paper.pdf">
            <span style="color: balck; font-weight;">Adversarial Backdoor Attack by Naturalistic Data Poisoning on Trajectory Prediction in Autonomous Driving </span>
            </a></h3>
          <p>
            <span style="color: black; font-weight: bold;">Mozhgan Pourkeshavarz</span>, Mohammad Sabokrou, Amir Rasouli<br>
            <i>Conference on Computer Vision and Pattern Recognition (<a href="https://cvpr.thecvf.com/virtual/2024/index.html">CVPR 2024</a>)</i><br>
<!--            <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Pourkeshavarz_Adversarial_Backdoor_Attack_by_Naturalistic_Data_Poisoning_on_Trajectory_Prediction_CVPR_2024_paper.pdf">PDF</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;-->
          </p>
        </div>
      </div>


        <div class="list-item publication" data-category="publication">
        <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Pourkeshavarz_CaDeT_a_Causal_Disentanglement_Approach_for_Robust_Trajectory_Prediction_in_CVPR_2024_paper.pdf" class="thumbnail">
            <img src="images/cadet.png" alt="" />
        </a>
        <div class="project-description">
          <h3><a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Pourkeshavarz_CaDeT_a_Causal_Disentanglement_Approach_for_Robust_Trajectory_Prediction_in_CVPR_2024_paper.pdf">
            <span style="color: balck; font-weight;">CaDeT: a Causal Disentanglement Approach for Robust Trajectory Prediction in Autonomous Driving</span>
            </a></h3>
          <p>
            <span style="color: black; font-weight: bold;">Mozhgan Pourkeshavarz</span>, Junrui Zhang, Amir Rasouli<br>
            <i>Conference on Computer Vision and Pattern Recognition (<a href="https://cvpr.thecvf.com/virtual/2024/index.html">CVPR 2024</a>)</i><br>
<!--            <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Pourkeshavarz_CaDeT_a_Causal_Disentanglement_Approach_for_Robust_Trajectory_Prediction_in_CVPR_2024_paper.pdf">PDF</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;-->
          </p>
        </div>
      </div>

              <div class="list-item publication" data-category="publication">
        <a href="https://arxiv.org/pdf/2310.07794" class="thumbnail">
            <img src="images/criteria.png" alt="" />
        </a>
        <div class="project-description">
          <h3><a href="https://ieeexplore.ieee.org/abstract/document/10610911">
            <span style="color: balck; font-weight;">Criteria: a new benchmarking paradigm for evaluating trajectory prediction models for autonomous driving</span>
            </a></h3>
          <p>
            Changhe Chen, <span style="color: black; font-weight: bold;">Mozhgan Pourkeshavarz</span>, Amir Rasouli<br>
            <i>International Conference on Robotics and Automation (<a href="https://2024.ieee-icra.org/">ICRA 2024</a>)</i><br>
            <a href="https://arxiv.org/pdf/2310.07794">Arxiv</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
          </p>
        </div>
      </div>


              <div class="list-item publication" data-category="publication">
        <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.pdf" class="thumbnail">
            <img src="images/tarot.png" alt="" />
        </a>
        <div class="project-description">
          <h3><a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.pdf">
            <span style="color: balck; font-weight;">Learn TAROT with MENTOR: A Meta-Learned Self-supervised Approach for Trajectory Prediction</span>
            </a></h3>
          <p>
             <span style="color: black; font-weight: bold;">Mozhgan Pourkeshavarz</span>, Changhe Chen, Amir Rasouli<br>
            <i>
              International Conference on Computer Vision (<a href="https://iccv2023.thecvf.com/">ICCV 2023</a>)</i><br>
<!--            <a href="https://openaccess.thecvf.com/content/ICCV2023/papers/Pourkeshavarz_Learn_TAROT_with_MENTOR_A_Meta-Learned_Self-Supervised_Approach_for_Trajectory_ICCV_2023_paper.pdf">PDF</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;-->
          </p>
        </div>
      </div>

              <div class="list-item publication" data-category="publication">
        <a href="https://openreview.net/pdf?id=RxplU3vmBx" class="thumbnail">
            <img src="images/lookback.png" alt="" />
        </a>
        <div class="project-description">
          <h3><a href="https://openreview.net/pdf?id=RxplU3vmBx">
            <span style="color: balck; font-weight;">Looking back on learned experiences for class/task incremental learning</span>
            </a></h3>
          <p>
             <span style="color: black; font-weight: bold;">Mozhgan Pourkeshavarz</span>, Guoying Zhao, Mohammad Sabokrou<br>
            <i>
              International Conference on Learning Representations (<a href="https://iclr.cc/virtual/2022">ICLR 2022</a>, <span style="color: red; font-weight: bold;">Spotlight</span>)</i><br>
          </p>
        </div>
      </div>

              <div class="list-item publication" data-category="publication">
        <a href="https://arxiv.org/pdf/2404.12538" class="thumbnail">
            <img src="images/tract.png" alt="" />
        </a>
        <div class="project-description">
          <h3><a href="https://ieeexplore.ieee.org/document/10588635">
            <span style="color: balck; font-weight;">TrACT: A Training Dynamics Aware Contrastive Learning Framework for Long-tail Trajectory Prediction</span>
            </a></h3>
          <p>
            Junrui Zhang, <span style="color: black; font-weight: bold;">Mozhgan Pourkeshavarz</span>, Amir Rasouli<br>
            <i>
              IEEE Intelligent Vehicles Symposium (<a href="https://ieee-iv.org/2024/">IV 2024</a>)</i><br>
            <a href="https://arxiv.org/pdf/2404.12538">Arxiv</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;
          </p>
        </div>
      </div>

              <div class="list-item publication" data-category="publication">
        <a href="https://arxiv.org/pdf/2302.04676" class="thumbnail">
            <img src="images/stack.png" alt="" />
          </video>
        </a>
        <div class="project-description">
          <h3><a href="https://link.springer.com/article/10.1007/s11042-023-15869-x">
            <span style="color: balck; font-weight;">Stacked cross-modal feature consolidation attention networks for image captioning</span>
            </a></h3>
          <p>
            <span style="color: black; font-weight: bold;">Mozhgan Pourkeshavarz</span>, Shahabedin Nabavi, Mohsen Ebrahimi Moghaddam, Mehrnoush Shamsfard<br>
            <i>
              Multimedia Tools and Applications (2020)</i><br>
<!--            <a href="https://arxiv.org/pdf/2302.04676">PDF</a>&nbsp;&nbsp;&bull;&nbsp;&nbsp;-->
          </p>
        </div>
      </div>

      <!-- Talks -->
      <div class="list-item talk" data-category="talk">
        <!-- Talk items -->
      </div>

      <!-- Miscellaneous -->
      <div class="list-item misc" data-category="misc">
        <!-- Misc items -->
      </div>
    </div>

  </div>

  <script>
  // Initialize Isotope and set default filter to `.talk`.
  var $grid = $('.grid').isotope({
    itemSelector: '.list-item',
    layoutMode: 'fitRows',
    filter: '.talk' // Default filter
  });

  // Handle filter button click.
  $('#filters').on('click', 'button', function () {
    var filterValue = $(this).attr('data-filter'); // Get selected filter
    $grid.isotope({ filter: filterValue }); // Apply filter
  });

  // Update button states.
  $('.button-group').each(function (i, buttonGroup) {
    var $buttonGroup = $(buttonGroup);
    $buttonGroup.on('click', 'button', function () {
      $buttonGroup.find('.is-checked').removeClass('is-checked');
      $(this).addClass('is-checked');
    });
  });

  // Ensure correct button is highlighted on page load.
  $(document).ready(function () {
    $('.button[data-filter=".talk"]').addClass('is-checked'); // Set Talks button as selected
  });

      // Automatically add `target="_blank"` to all links.
  document.querySelectorAll('a').forEach(function(link) {
    link.setAttribute('target', '_blank');
  });
</script>

</body>

</html>
